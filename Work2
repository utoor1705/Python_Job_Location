# Required Packages
import pandas as pd
import numpy as np
import nltk
from nltk.tokenize import word_tokenize
from nltk.tokenize.treebank import TreebankWordDetokenizer

# Loading our main data file and Occupation data file.
df = pd.read_csv('data_full.csv', engine='python', encoding='utf-8', error_bad_lines=False)
df1 = pd.read_csv('occupation-list.csv')

# Cleaning main data file.
df = df.loc[:, ~df.columns.str.contains('^Unnamed')]
title_data = df[df['Title'].notnull()].copy()

# Initializing all values to 0 for the new Column 'Occupiation'.
title_data["Occupation"] = 0

# Note 1 if Occupation names was mentioned in the titles
for i in range(len(title_data['Title'])):
    title_data['Title'].values[i] = title_data['Title'].values[i].lower()
    title_data['Title'].values[i] = word_tokenize(title_data['Title'].values[i])
    for j in range(len(df1['Occupation'])):
        if df1['Occupation'].values[j].lower() in title_data['Title'].values[i]:
            title_data["Occupation"].values[i] = 1

# Untokenzie values previously Tokenized.  
for i in range(len(title_data['Title'])):
    title_data['Title'].values[i] = TreebankWordDetokenizer().detokenize(title_data['Title'].values[i])

# Occupation file generated.
output = title_data.to_csv('Occupation.csv', index=None, header=True)
